{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32403500",
   "metadata": {},
   "source": [
    "Stable Diffusion is a text-to-image latent diffusion model created by the researchers and engineers from CompVis, Stability AI and LAION. It's trained on 512x512 images from a subset of the LAION-5B database. This model uses a frozen CLIP ViT-L/14 text encoder to condition the model on text prompts. With its 860M UNet and 123M text encoder, the model is relatively lightweight and runs on a GPU with at least 10GB VRAM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79dac3",
   "metadata": {},
   "source": [
    "Setup\n",
    "Please make sure you are using a GPU runtime to run this notebook, so inference is much faster. If the following command fails, use the Runtime menu above and select Change runtime type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c044f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d8cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install diffusers==0.4.0\n",
    "!pip install transformers scipy ftfy\n",
    "!pip install \"ipywidgets>=7,<8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54405948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce4903e",
   "metadata": {},
   "source": [
    "Load the pre-trained weights of https://huggingface.co/CompVis/stable-diffusion-v1-4 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "# make sure you're logged in with `huggingface-cli login`\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a photograph of an astronaut riding a horse\"\n",
    "image = pipe(prompt).images[0]  # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
    "\n",
    "# Now to display an image you can do either save it such as:\n",
    "image.save(f\"astronaut_rides_horse.png\")\n",
    "\n",
    "# or if you're in a google colab you can directly display it with \n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5f4118",
   "metadata": {},
   "source": [
    "Running the above cell multiple times will give you a different image every time. If you want deterministic output you can pass a random seed to the pipeline. Every time you use the same seed you'll have the same image result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc365aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "generator = torch.Generator(\"cuda\").manual_seed(1024)\n",
    "\n",
    "image = pipe(prompt, generator=generator).images[0]\n",
    "\n",
    "image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400545a9",
   "metadata": {},
   "source": [
    "To generate multiple images for the same prompt, we simply use a list with the same prompt repeated several times. We'll send the list to the pipeline instead of the string we used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841a4c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0bf322",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = 3\n",
    "num_rows = 4\n",
    "\n",
    "prompt = [\"a photograph of an astronaut riding a horse\"] * num_cols\n",
    "\n",
    "all_images = []\n",
    "for i in range(num_rows):\n",
    "  images = pipe(prompt).images\n",
    "  all_images.extend(images)\n",
    "\n",
    "grid = image_grid(all_images, rows=num_rows, cols=num_cols)\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8456c8",
   "metadata": {},
   "source": [
    "And here's how to generate a grid of n Ã— m images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf1ff01",
   "metadata": {},
   "source": [
    "Generating captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1907cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b11d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bfdee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ebab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = ['airplane', 'bicycle', 'boat', 'bus',\n",
    "           'car', 'dog', 'motorcycle', 'person', 'train', 'truck']\n",
    "\n",
    "prompts = []\n",
    "\n",
    "fr = open('prompts.txt','r')\n",
    "for fl in fr:\n",
    "    prompts += fl.strip().split(',')\n",
    "\n",
    "print(prompts)\n",
    "n_predictions = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8cdb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, n_predictions):\n",
    "    for i, prompt in enumerate(prompts):\n",
    "\n",
    "        with autocast(\"cuda\"):\n",
    "            image = pipe(prompt, height=128, width=128)[\"sample\"][0]  \n",
    "                \n",
    "        now = datetime.now()\n",
    "        time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        img_name = CLASS_NAMES[i] + \"_\" + time + \".png\"\n",
    "\n",
    "        # print(\"***\" + \"generated_images/images/\" + prompt + \"/\" + img_name +  \"***\")\n",
    "\n",
    "        # image.save(\"generated_images_prompting/images/\" + CLASS_NAMES[i] + \"/\" + img_name)\n",
    "        image.save(\"images/\" + CLASS_NAMES[i] + \"/\" + img_name)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(str(i) + \" completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
