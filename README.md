# Data Augmentation using Stable Diffusions for inmproving Object Detection performance.

![Architecture](https://github.com/ruthvikauwm/ObjectDetection/assets/54182107/67582425-67b5-45e7-8a86-863f5e4c682c)

**Dataset Curation**
Dataset is curated from 3 parts, the original set, the synthetic set, and the test set.
1. **Original dataset** -  COCO 2017 dataset, contains over 330,000 images with more than
2.5 million object instances labeled across 80 categories.
2. **Synthetic dataset** - Generated by passing prompts to the Stable Diffusion model and its
fine-tuned versions, as well as including images generated from GANs. Labeled the
synthetic images usingthe makesense.ai website. 
3. **Test Set** - Images from a similar distribution to the original set.

**Dataset Augmentation**
1. **GANs** -  We chose ICGAN (Image-to-Image Translation Conditional GAN) which can produce
targeted image outputs based on specific conditions. Generated multi-breed dog images by
providing an input image for reference or specifying an input image class for reference.
2. **Stable Diffusion** - Using the most recent version of thestable diffusion made available
by the renowned Huggingface library. Will train the YOLO dataset on a chosen dataset.
A neural captioning model was used to generate neural captions which was fed to this model
to generate images. Once there is a caption for each image, the stable diffusion model was
used to generate a synthetic image that accurately reflects the content of the caption. 

**Object Detection**
We used the Transfer learning technique to train a custom dataset on the YOLOv5 model. 
This technique eases the task as training a model from scratch is usually time-consuming 
and may not yield good results. By using pre-trained models and fine-tuning them on a 
custom dataset, the model's performance can be improved significantly.
