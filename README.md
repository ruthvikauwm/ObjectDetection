# Data Augmentation using Stable Diffusions for improving Object Detection performance

**Introduction**
Object detection is a crucial task in computer vision, with applications in various domains such as autonomous driving, surveillance, and medical imaging. Deep learning models have shown remarkable performance in this task, but their effectiveness relies on large and diverse datasets for training. Collecting such datasets is expensive, time-consuming, and prone to bias and class imbalance issues. To address this challenge, this project proposes a novel approach to synthetic image data augmentation using Large Language Models (LLMs). The project aims to fill the gap in existing research by exploring advanced techniques to generate high-quality synthetic images for improving object detection.

**Proposed Method**

![Architecture](https://github.com/ruthvikauwm/ObjectDetection/assets/54182107/67582425-67b5-45e7-8a86-863f5e4c682c)

**Dataset Curation**
Dataset is curated from 3 parts, the original set, the synthetic set, and the test set.
1. **Original dataset** -  COCO 2017 dataset, contains over 330,000 images with more than
2.5 million object instances labeled across 80 categories.
2. **Synthetic dataset** - Generated by passing prompts to the Stable Diffusion model and its
fine-tuned versions, as well as including images generated from GANs. Labeled the
synthetic images usingthe makesense.ai website. 
3. **Test Set** - Images from a similar distribution to the original set.

**Dataset Augmentation**
1. **GANs** -  We chose ICGAN (Image-to-Image Translation Conditional GAN) which can produce
targeted image outputs based on specific conditions. Generated multi-breed dog images by
providing an input image for reference or specifying an input image class for reference.
2. **Stable Diffusion** - Using the most recent version of thestable diffusion made available
by the renowned Huggingface library. Will train the YOLO dataset on a chosen dataset.
A neural captioning model was used to generate neural captions which was fed to this model
to generate images. Once there is a caption for each image, the stable diffusion model was
used to generate a synthetic image that accurately reflects the content of the caption. 

**Object Detection**
We used the Transfer learning technique to train a custom dataset on the YOLOv5 model. 
This technique eases the task as training a model from scratch is usually time-consuming 
and may not yield good results. By using pre-trained models and fine-tuning them on a 
custom dataset, the model's performance can be improved significantly.
